                             ğŸ—£ï¸ Accent Recognition using Machine Learning

Predict the speakerâ€™s accent from audio using MFCCs, audio augmentation, and classical ML models.

This project predicts the accent of a speaker from a .wav audio sample using machine learning.
It is built as a complete end-to-end pipeline including:

ğŸ§ Audio preprocessing and augmentation

ğŸ” Feature extraction (MFCC, ZCR, RMSE)

ğŸ§  Model training and evaluation (Random Forest / Logistic Regression)

ğŸ§ª Data versioning via DVC

ğŸŒ Streamlit app for real-time accent prediction


ğŸ“‚ Project Structure
 ``` bash 
Accent-Recognition/
â”‚
â”œâ”€â”€ .dvc/                                # DVC internal files
â”œâ”€â”€ .gitignore                           # Ignore data, models, cache files
â”œâ”€â”€ dvc.yaml                             # DVC pipeline config (custom stages)
â”œâ”€â”€ dvc.lock                             # Auto-generated DVC lock file
â”‚
â”œâ”€â”€ data/                                # All dataset-related files
â”‚   â”œâ”€â”€ raw/                             # Raw .wav audio files
â”‚   â”œâ”€â”€ interim/                         # Feature CSVs (e.g., MFCCs)
â”‚   â”œâ”€â”€ processed/                       # Cleaned/structured data (optional)
â”‚   â””â”€â”€ raw.dvc                          # DVC tracking file for raw data
â”‚
â”œâ”€â”€ models/                              # Trained ML models
â”‚   â””â”€â”€ model.joblib                     # Final serialized model
â”‚
â”œâ”€â”€ artifacts/                           # Saved encoders, scalers, etc.
â”‚   â”œâ”€â”€ preprocessor.joblib              # Scaler or transformation pipeline
â”‚   â””â”€â”€ label_encoder.joblib             # LabelEncoder for accent labels
â”‚
â”œâ”€â”€ src/                                 # Source code for all components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py                     # Global constants and paths
â”‚   â”œâ”€â”€ logger.py                        # Logging configuration
â”‚   â”œâ”€â”€ from_root.py                     # Utility to resolve absolute paths
â”‚
â”‚   â”œâ”€â”€ utils/                           # Reusable utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main_utils.py                # save/load objects, dataframe utils
â”‚
â”‚   â”œâ”€â”€ components/                      # Core ML components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py        # Data cleaning/preprocessing
â”‚   â”‚   â”œâ”€â”€ data_augmentation.py         # Audio augmentation (noise, pitch, etc.)
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py        # MFCC/ZCR/RMSE extractor
â”‚   â”‚   â”œâ”€â”€ model_training.py            # Training models
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py          # Accuracy, confusion matrix, scores
â”‚   â”‚   â””â”€â”€ visualisation.py             # Learning curves, plots, etc.
â”‚
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ prediction_pipeline.py , trainning_pipeline.py    model
|        
â”‚
â”œâ”€â”€ app.py                               # Streamlit app for accent prediction
â”œâ”€â”€ requirements.txt                     # All required Python dependencies
â”œâ”€â”€ README.md                            # Project overview and usage
â””â”€â”€ setup.py                             # (Optional) Package installation file
â”œâ”€â”€ dvc.yaml                             
â””â”€â”€ params.yaml                           
â”œâ”€â”€ project.toml                            
â””â”€â”€ ddvc.lock 
etc
```
  

ğŸ“Š Features Extracted
From each audio file, we extract:

MFCCs (13 coefficients) â€” Mel Frequency Cepstral Coefficients

ZCR â€” Zero Crossing Rate

RMSE â€” Root Mean Square Energy

ğŸ”„ Audio Augmentation

To improve model generalization, we apply:

ğŸµ Time stretching

ğŸ“ˆ Pitch shifting

ğŸ”Š Noise addition

This ensures robustness to variations in speech.

ğŸ¤– Model Training

Models Compared:

RandomForestClassifier

LogisticRegression (final selected)

Evaluation Metrics:

Accuracy

Confusion matrix

Learning curve

Final Model: Logistic Regression

Test Accuracy: ~96%

ğŸ“¦ Version Control with DVC

used DVC to version:

Raw & interim datasets

Feature-engineered files

Trained models

``` bash 
dvc init
dvc add data/raw
dvc repro
```

ğŸŒ Web App Interface (Streamlit)

Upload a .wav audio

See waveform and spectrogram

View predicted accent + confidence

Works on local or remote deployment


ğŸ“ˆ Future Enhancements (Optional)

ğŸ”‰ Add accent conversion via TTS for demo/playback

ğŸ™ï¸ Live mic input + real-time prediction

ğŸ“¦ Deploy via Streamlit Cloud or Hugging Face Spaces

ğŸ§ª How to Run

âœ… Install dependencies:

```bash
pip install -r requirements.txt
```

âœ… Run Streamlit app:

```bash
streamlit run app.py
```

ğŸ‘¨â€ğŸ’» Author
Himanshu Singh
Second-Year B.Tech ECE @ IIIT Una
GitHub: [@Himanshu0518](https://github.com/Himanshu0518)
DagsHub: [@himanshu0518](https://dagshub.com/Himanshu0518)

### ğŸ“Š MLflow Tracking

To explore model parameters, metrics, and experiment runs:

[![MLflow Tracking](https://img.shields.io/badge/MLflow-enabled-blue)](https://dagshub.com/Himanshu0518/Accent-Recognition.mlflow/#/experiments/0?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D)

