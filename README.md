# ğŸ—£ï¸ Accent Recognition using Machine Learning

Predict the speakerâ€™s accent from audio using MFCCs, data augmentation, and classical machine learning techniques.

This project is built as an end-to-end MLOps pipeline that includes:

- ğŸ§ **Audio preprocessing** & **augmentation**
- ğŸ” **Feature extraction** (MFCC, ZCR, RMSE)
- ğŸ¤– **Model training** and **evaluation**
- ğŸ“¦ **Data versioning via DVC**
- ğŸŒ **Streamlit app** for real-time accent prediction
- ğŸš€ **CI/CD Deployment** on **AWS EC2** using **GitHub Actions**
- ğŸ“Š **MLflow tracking**
- ğŸ“ **Custom dataset**, collected and published on [Kaggle](https://www.kaggle.com/)

---

## ğŸ“¥ Data Collection

All accent audio data was collected manually using Python-based scripts. The raw `.wav` files were then preprocessed and labeled appropriately. The finalized dataset has been published publicly on **Kaggle** for reproducibility and benchmarking.

---

## ğŸ“‚ Project Structure

```bash
Accent-Recognition/
â”‚
â”œâ”€â”€ .dvc/                     # DVC internal files
â”œâ”€â”€ dvc.yaml                  # DVC pipeline stages
â”œâ”€â”€ dvc.lock                  # DVC lock file
â”œâ”€â”€ data/                     # Dataset directories
â”‚   â”œâ”€â”€ raw/                  # Raw .wav files
â”‚   â”œâ”€â”€ interim/              # Extracted features (CSV)
â”‚   â”œâ”€â”€ processed/            # Cleaned dataset
â”‚   â””â”€â”€ raw.dvc               # DVC tracking file
â”‚
â”œâ”€â”€ models/                   # Serialized ML models
â”‚   â””â”€â”€ model.joblib
â”‚   â””â”€â”€ preprocessor.joblib
â”‚   â””â”€â”€ labelencoder.joblib
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ constants.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ from_root.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â”œâ”€â”€ data_augmentation.py
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”œâ”€â”€ model_training.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â””â”€â”€ visualisation.py
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ prediction_pipeline.py
â”‚       â””â”€â”€ trainning_pipeline.py
â”‚
â”œâ”€â”€ app.py                   # Streamlit web app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ params.yaml
â””â”€â”€ README.md
```
## ğŸ› Features Extracted

ğŸµ MFCCs â€“ Mel-Frequency Cepstral Coefficients

ğŸšï¸ ZCR â€“ Zero Crossing Rate

ğŸ’¡ RMSE â€“ Root Mean Square Energy


## ğŸ”„ Audio Augmentation

To improve model robustness:

â±ï¸ Time Stretching

ğŸ¤ Pitch Shifting

ğŸ“¢ Noise Injection

These augmentations increase diversity and generalizability across speaker conditions.


## ğŸ¤– Model Training

Models Compared:

RandomForestClassifier

LogisticRegression 


## Evaluation Metrics:

Accuracy

Confusion Matrix

Learning Curve

âœ… Final Model: Logistic Regression

âœ… Test Accuracy: ~96%


## ğŸ“¦ Data Versioning with DVC

To ensure reproducibility and data tracking:

```bash
dvc init
dvc add data/raw
dvc repro
```
All stages â€” from raw data to feature extraction to final model â€” are versioned with DVC.


## ğŸŒ Web Application 

A simple and interactive flask app allows users to:

Upload a .wav audio file

Visualize waveform & spectrogram

Get real-time accent prediction


## ğŸ§ª CI/CD Deployment (AWS EC2 + Docker + GitHub Actions)

Dockerized app is built and pushed to Amazon ECR

On every push to main, GitHub Actions triggers:

âœ… CI: Docker Build â†’ Push to ECR

âœ… CD: SSH into EC2 â†’ Pull & Run Docker container

âœ… EC2 Port: 8000


### ğŸ“Š MLflow Tracking

To explore model parameters, metrics, and experiment runs and model registry :

[![MLflow Tracking](https://img.shields.io/badge/MLflow-enabled-blue)](https://dagshub.com/Himanshu0518/Accent-Recognition.mlflow/#/experiments/0?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D)


ğŸ§± How to Run This Project

** 1. Install Dependencies **
```bash
pip install -r requirements.txt
```

** Run flask App **
```bash
python app.py
```

**ğŸ³ Run via Docker**
(preferred)
You can directly pull and run the app using Docker:

ğŸ”» Pull Docker Image
```bash
docker pull himanshu0518/accent-recognition-app:latest
```

Run the container

```bash
docker run -p 8000:8000 himanshu0518/accent-recognition-app:latest
```

## ğŸ¯ Future Improvements

ğŸ™ï¸ Real-time accent detection from microphone input

ğŸ” Accent-to-Accent TTS conversion


## ğŸ‘¨â€ğŸ’» Author

**Himanshu Singh**  

Pre-final year B.Tech ECE @ IIIT Una

- ğŸ™ GitHub: [@Himanshu0518](https://github.com/Himanshu0518) 

- ğŸ“Š DagsHub: [@Himanshu0518](https://dagshub.com/Himanshu0518/Accent-Recognition)  

- ğŸ³ DockerHub: [himanshu0518/accent-detector](https://hub.docker.com/repository/docker/himanshu0518/accent-recognition-app/general)

âš ï¸ Disclaimer
The project is currently deployed using AWS Free Tier services. The services are removed after testing to save credits.